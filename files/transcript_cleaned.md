ever wish you could automatically generate lecture notes from your lecture videos? or maybe you're tired of writing meeting minutes. i know i am. well, in this video, we're gonna solve that completely. what's happening guys, my name's nicholas, or not in this video, we're gonna be taking a look at video to text. interested? let's take a look in greater detail as to what we're going to be going through. so in this video, we're going to be converting video to text. so we're first out going to start out by using the youtube dl library that download virtually any youtube video. we're then going to pre-process that video to audio using the ffm page library. so this is really easy and it'll allow you to rip out the audio out of any video. we're then going to convert that video to text using the watson speech to text service for free. and then we're going to be outputting those results from that conversion into a text file. so you'll then have a full blown transcript that you can then go away and use without having to worry about it. so in terms of how we're going to be doing this, we're going to be mainly working inside of a jupyter notebook. so we'll first start out by extracting our audio from our video that we've already downloaded using the youtube dl functionality. we'll then convert it using the watson speech to text service. and last but not least, we're going to push that out using the native python functionality to create a text file. ready to do it? let's get to it. so in this video, we're going to be focused on converting a video all the way through to text. now we're mainly going to be working in python. so i've already got a jupyter notebook up here. now our core steps that we're going to be going through installing and importing dependencies, extracting our audio using ffmpeg, then creating our speech to text service, converting it to text, and outputting it to a txt file. now in this case, we're going to add in one additional step which i haven't included here, and that's grabbing a video. so say, for example, we had a youtube video that we wanted to grab. well, we can actually grab that using the youtube dl library. this is probably one of my favorite libraries. it allows you to grab youtube videos and convert your own videos or convert other videos if you want to grab some notes. so in order to install youtube dl, we just need to open up a new terminal and then type in pip install youtube dl. so this is going to go through install everything that you need. you obviously need python in order to use pip install command, but that should install it for you. then all you need to do is type in youtube dl and then grab a link of the video that you want. so in this case, i've got my ai versus machine learning versus data science video, and we can grab that link, paste it after the youtube dl command and hit enter. this is going to go through and start downloading our video. now, it's going to download it in your home directory, but then we can grab it and put it inside of the same directory that we've got our jupyter notebook. so let's let that download and then we can get started. okay, so our video is now downloaded. we can hit open, and this is going to open it up in the same directory. so you can see here, we've got ai versus machine learning versus deep learning dot make v. so we can copy that over into our video to text folder. now, i'm just going to rename it to make our lives a little bit easier when we actually start working with this file. so we'll just call it a iml dot make v. all right, cool. so that is our video file done. now we can get into the good bit. so the first thing that we're going to do is first up install dependencies. now, we've got two key dependencies here. we need to have the ibm watson services and we also need to install ffm peg. so ffm peg is basically a library that helps you work with a whole bunch of video files and audio files. and we're going to use it to extract the audio from our video in order to send it to the watson speech to text service. so we can install those dependencies within our jupyter notebook. so let's go ahead and do that. okay, so i've gone ahead and installed those dependencies. now, in order to do that, we've used the pip install ibm watson command and i've commented it out. but if you wanted to install ffm peg, you just need to type in brew install ffm peg. if you're on a mac, if you're on a windows machine, there's some additional steps on this link. but again, i'll include the link to this in order to install it as well as a full github repo for this tutorial in the description below. so now that that's installed, what we can then go and do is import our dependencies. so in this case, we're going to be using the ibm watson dependencies plus we're going to be using subprocess to actually perform our audio extraction. so let's bring in our dependencies first up. so those are our dependencies imported. so we've gone ahead and imported a couple of things there. so first up, we imported subprocess and this is going to allow us to make a subprocess call using our regular terminal. then we've imported the speech to text class from ibm watson and this is going to be used to actually connect to our speech to text service. we've also imported a couple of helpers here. so recognize callback as well as audio source again from ibm watson. and last but not least, we've imported iam authenticated. so this is going to allow us to authenticate against our speech to text service once we set that up. now the next thing that we're going to do is actually extract our audio. so remember when we extracted our video, we had this ai ml video here. now what we want to do first is take that video and extract the audio from it so we can then convert speech to text. so let's go ahead and do that. and in order to do that, we're going to be using ffnpeg. all righty, so we've now gone and extracted our audio. now in terms of what we've actually done here, we've passed through a command and that command is basically calling our ffnpeg library. we're passing through the name of the file that we want to extract our audio from, the bit rate as well as the frequency and then last but not least, we've specified what we want the file name to be. so if you haven't downloaded a youtube video or you want to use your own video, all you need to do is specify a different file name here. and this just needs to be the file that you're trying to convert. then what we've done is we've gone and called that command using our subprocess library and we've used our shell. so now if we take a look within our folder, we've got a file called audio.wav. so this is our audio file. so if we actually play that, ever wondered about the differences between ai? so you can see that we've now extracted the audio from our video. now the next step is to start setting up our watson speech detect service. so in this case, we're going to be using a free watson service so you'll be able to convert up to, i think it's 500 minutes of free speech detects per month. so let's go on ahead and start setting that up. now in this case, the first thing that we need to do is grab two variables. so we're going to need an api key as well as a url. now in order to get an api key and a url, you just need to go to cloud.ibm.com, forward slash catalog, then hit services. so over here and then scroll on down to ai and machine learning. and this is where you'll see all the ai and machine learning services. and then from there, you'll be able to see speech to text. so if you select speech to text, you can see that there'll be a whole heap of pricing plans that show up, but we just need this light plan here. and as i said, you get 500 free minutes per month to convert. so that's more than enough if you're just getting started. so choose that plan and then go in ahead and hit create. and as soon as this surface is created, you'll be able to extract your api key as well as your url and plug it back into your notebook. so now that that's created, we can just go to manage over here. so you'll start out on getting started. you just need to hit manage and then grab your api key down there. so we can just hit these copy buttons down here, copy, copy, copy, and we'll grab our api key first up. and then we'll store that in our variable here. and then likewise, we'll go and grab our url. awesome. now that's done. now what we need to do is actually start setting up our speech to text service. so let's go ahead and do that. so that is our service set up. so in those three lines, what we first did is we created a new iam authenticator. and to that, we passed our api key, which is this variable up here. and that's the same one that we got from our ibm cloud service. we then went and created a new speech to text service and passed through our authenticator, which is this variable here. and then we also set our service url. so this is basically telling our speech to text service or our speech to text variable inside of our jupyter notebook. where is our service inside of the worldwide web? so that's basically all set up. now now what we can actually go and do is start converting our audio. so let's delete that cell there and create a couple of new cells below that. and then what we can do is create our conversion. so in order to do this, we're going to be using the speech to text.recognize method. and we're basically going to be passing through our audio.wav file and converting that to text. we'll then be able to pre-process the results and output it to a txt file. so let's go on ahead and start performing that conversion. so that's basically our conversion code done. now before we actually go and run that, let's take a quick look at what we've actually written. so first up what we're doing is we're opening up our audio.wav file. and then we're using the speech to text service that we set up here. so speech to text variables coming from there. and we're using the recognize method to go and convert that speech to text. so we're passing through a bunch of commands. so in this case, we're setting our audio to a file that we just specified up here. we're also specifying the content type. so because our file has a.wav extension, we're just saying that we're going to be sending a wav extension, then we're also passing through the model. so this is the language model that we want to use. and in this case, there's a whole bunch that are available through the watson speech to text service. but again, i'll include a link to this in the description. so you can grab this and take a look at it. then last but not least, we're using, we're passing through the continuous flag and we're getting our result. so ideally, once we run this cell, it's going to go and process our audio and bring us back some text. so let's go on ahead and run that. now it might take a couple of minutes to run. it'll vary depending on how long your video is. five minutes later. alrighty, and that's our conversion done. now we haven't actually output anything to the screen, but it's all stored within our res variable here. so if we actually type in res and open that up, you can see we've got our converted audio. that is brilliant. now it did take a couple of minutes to process, but keep in mind that our video was around about eight minutes long. so it wasn't too bad. now if we actually wanted to go and pre-process this and output it to a text file, we can actually loop through each one of these transcriptions and now output it. so if we want, we can create a couple of extra cells. and then if we actually take a look at our result keys, we can take a look at that. you can see that we've got two keys. so we've got result index and we've got results. now if we actually open up our results section, you can see that all of our results are actually stored in there. but there's actually a couple of different results. and that's because what the speech or text service does is it breaks it out into paragraphs. now we can actually loop through each one of these and extract them and then push them out to a text file. so let's go ahead and do that. so what we're basically going to be doing is looping through our res results array and we're going to be pre-processing each one of those results and then storing it inside of another array and then we'll do a little bit of pre-processing, push it out to our text file. and there we go. so what we've now got is all of our transcriptions inside of a big text array. so if we take a look, we should have eight paragraphs. and you can see we've got eight paragraphs. now what we can do is do a little bit of cleaning up. so what we'll do is we'll strip out any white space and we'll concatenate them all together and push it out to a text file. and there you go. so now if we take a look, you can see that we've got our output.text file here. and all of our video has now been transcoded. so we started out with our youtube video that we downloaded, we converted it to make v, we then extracted our audio and we've gone all the way and generated our transcription. now in terms of those last couple of lines of code that we wrote, what i was basically doing is we take our first letter within each sentence and i was basically adding a title case so that basically makes it a little bit cleaner. and then what we're doing is we're joining each one of those together to get one big text block. so if we take a look at our transcript, you can see that it's everything together rather than having multiple paragraphs. and then last but not least, we're writing it out to a text file here. and that about wraps up this video. so just to quickly recap, we went and downloaded a video from youtube using the youtube dl library. we then went and imported all of our dependencies, extracted our audio using ffmpeg. we set up a speech to text service and converted our video to speech. and then we output our speech to a text file. so you've now effectively got a full blown video transcript that you can take away and use. thanks so much for tuning in guys. hopefully you found this video useful. if you did, be sure to give it a thumbs up, hit subscribe and tick that bell so you get notified of when i release future videos. and all the assets included within the video are going to be linked in the description below, as well as a github repository with all the code you need to get. kickstart it on your way to performing video to text. and let me know in the comments below what you're using video to text for. thanks again for tuning in, bye.